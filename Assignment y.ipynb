{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4MBuZzSNZ-3",
        "outputId": "e5a3f705-d5ae-4286-de84-bbe4c7fab1d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Demo: Conversation Flow ===\n",
            "\n",
            "--- Conversation History ---\n",
            "user: Hello! I'm Alex and I need assistance with my development task.\n",
            "\n",
            "--- Conversation History ---\n",
            "user: Hello! I'm Alex and I need assistance with my development task.\n",
            "assistant: Hi Alex! I'm here to help. What kind of development task are you working on?\n",
            "\n",
            "[Summarizing conversation...]\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Got it—you're building a chat-summarization service on Groq. Let me know what part you need help with (API calls, prompt engineering, throughput, cost, etc.).\n",
            "user: I'm building a system that creates summaries of chats using the Groq platform.\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Got it—you're building a chat-summarization service on Groq. Let me know what part you need help with (API calls, prompt engineering, throughput, cost, etc.).\n",
            "user: I'm building a system that creates summaries of chats using the Groq platform.\n",
            "assistant: That sounds interesting! We'll need to handle conversation storage and create condensed versions.\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Got it—you're building a chat-summarization service on Groq. Let me know what part you need help with (API calls, prompt engineering, throughput, cost, etc.).\n",
            "user: I'm building a system that creates summaries of chats using the Groq platform.\n",
            "assistant: That sounds interesting! We'll need to handle conversation storage and create condensed versions.\n",
            "user: Exactly, and we should also limit message length when conversations get lengthy.\n",
            "\n",
            "[Summarizing conversation...]\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Hi Maya—happy to help with your AI research assignment. What specific aspect are you tackling next?\n",
            "user: Hi there! I'm Maya, working on an AI research assignment.\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Hi Maya—happy to help with your AI research assignment. What specific aspect are you tackling next?\n",
            "user: Hi there! I'm Maya, working on an AI research assignment.\n",
            "assistant: Hello Maya! I'd be glad to assist with your research. What's the focus area?\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Hi Maya—happy to help with your AI research assignment. What specific aspect are you tackling next?\n",
            "user: Hi there! I'm Maya, working on an AI research assignment.\n",
            "assistant: Hello Maya! I'd be glad to assist with your research. What's the focus area?\n",
            "user: It involves implementing automatic text condensation using Groq's language models.\n",
            "\n",
            "[Summarizing conversation...]\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Which sub-task would you like to tackle first—data handling, summarization logic, or something else?\n",
            "assistant: Excellent topic! This requires managing dialogue records and generating brief overviews.\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Which sub-task would you like to tackle first—data handling, summarization logic, or something else?\n",
            "assistant: Excellent topic! This requires managing dialogue records and generating brief overviews.\n",
            "user: Right, plus we need mechanisms to shorten content when it becomes excessive.\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Which sub-task would you like to tackle first—data handling, summarization logic, or something else?\n",
            "assistant: Excellent topic! This requires managing dialogue records and generating brief overviews.\n",
            "user: Right, plus we need mechanisms to shorten content when it becomes excessive.\n",
            "user: Good day! I'm Sam, and I'm stuck on my coursework assignment.\n",
            "\n",
            "[Summarizing conversation...]\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Let me know what’s stumping you and I’ll help you work through it.\n",
            "assistant: Hi Sam! What subject is your assignment focused on?\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Let me know what’s stumping you and I’ll help you work through it.\n",
            "assistant: Hi Sam! What subject is your assignment focused on?\n",
            "user: It's about creating intelligent text compression systems with Groq API integration.\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Let me know what’s stumping you and I’ll help you work through it.\n",
            "assistant: Hi Sam! What subject is your assignment focused on?\n",
            "user: It's about creating intelligent text compression systems with Groq API integration.\n",
            "assistant: Interesting challenge! You'll need to track conversations and produce concise summaries.\n",
            "\n",
            "[Summarizing conversation...]\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Got it. So the core tasks are:\n",
            "\n",
            "1. Intelligent text compression via Groq API\n",
            "2. Conversation/memory tracking\n",
            "3. Concise summary generation\n",
            "4. Message-volume control when discussions expand\n",
            "\n",
            "What’s the first piece that’s giving you trouble—prompt design, memory management, or the volume-control logic?\n",
            "user: Precisely, and implement features to control message volume when discussions expand.\n",
            "\n",
            "=== Demo: Truncation by last 2 turns ===\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Got it. So the core tasks are:\n",
            "\n",
            "1. Intelligent text compression via Groq API\n",
            "2. Conversation/memory tracking\n",
            "3. Concise summary generation\n",
            "4. Message-volume control when discussions expand\n",
            "\n",
            "What’s the first piece that’s giving you trouble—prompt design, memory management, or the volume-control logic?\n",
            "user: Precisely, and implement features to control message volume when discussions expand.\n",
            "\n",
            "=== Demo: Truncation by 50 characters ===\n",
            "\n",
            "--- Conversation History ---\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install --quiet openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"   # Groq API key\n",
        "os.environ[\"OPENAI_BASE_URL\"] = \"https://api.groq.com/openai/v1\"\n",
        "\n",
        "client = OpenAI()\n",
        "# 2. Conversation Storage\n",
        "\n",
        "conversation_history = []\n",
        "run_counter = 0\n",
        "\n",
        "def add_message(role, content):\n",
        "    \"\"\"Add user/assistant/system message to history\"\"\"\n",
        "    conversation_history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "def print_history():\n",
        "    \"\"\"Print conversation history\"\"\"\n",
        "    print(\"\\n--- Conversation History ---\")\n",
        "    for m in conversation_history:\n",
        "        print(f\"{m['role']}: {m['content']}\")\n",
        "# 3. Summarization Function\n",
        "\n",
        "def summarize_history(history):\n",
        "    \"\"\"Summarize entire conversation so far using Groq API\"\"\"\n",
        "    messages = [{\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in history]\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"moonshotai/kimi-k2-instruct-0905\",   # Used Moonshotai model (Groq-supported model)\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Summarize the following conversation concisely.\"},\n",
        "            *messages\n",
        "        ],\n",
        "        max_tokens=100\n",
        "    )\n",
        "    return completion.choices[0].message.content.strip()\n",
        "# 4. Truncation Options\n",
        "\n",
        "def truncate_by_turns(n):\n",
        "    \"\"\"Keep only the last n conversation turns\"\"\"\n",
        "    global conversation_history\n",
        "    conversation_history = conversation_history[-n:]\n",
        "\n",
        "def truncate_by_length(max_chars):\n",
        "    \"\"\"Keep only messages within max character length\"\"\"\n",
        "    global conversation_history\n",
        "    result, total_len = [], 0\n",
        "    for m in reversed(conversation_history):\n",
        "        if total_len + len(m[\"content\"]) <= max_chars:\n",
        "            result.insert(0, m)\n",
        "            total_len += len(m[\"content\"])\n",
        "        else:\n",
        "            break\n",
        "    conversation_history = result\n",
        "# 5. Periodic Summarization\n",
        "\n",
        "def on_new_run(role, content, k=3):\n",
        "    \"\"\"\n",
        "    Add message, increment run counter,\n",
        "    summarize every k-th run, replace history with summary + last message\n",
        "    \"\"\"\n",
        "    global run_counter, conversation_history\n",
        "\n",
        "    add_message(role, content)\n",
        "    run_counter += 1\n",
        "\n",
        "    if run_counter % k == 0:\n",
        "        print(\"\\n[Summarizing conversation...]\")\n",
        "        summary = summarize_history(conversation_history)\n",
        "        conversation_history = [{\"role\": \"system\", \"content\": f\"SUMMARY -> {summary}\"}]\n",
        "        conversation_history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "    print_history()\n",
        "# 6. Demonstration\n",
        "\n",
        "print(\"=== Demo: Conversation Flow ===\")\n",
        "\n",
        "#Technical Project Discussion\n",
        "on_new_run(\"user\", \"Hello! I'm Alex and I need assistance with my development task.\")\n",
        "on_new_run(\"assistant\", \"Hi Alex! I'm here to help. What kind of development task are you working on?\")\n",
        "on_new_run(\"user\", \"I'm building a system that creates summaries of chats using the Groq platform.\")  # triggers summarization at 3rd run\n",
        "on_new_run(\"assistant\", \"That sounds interesting! We'll need to handle conversation storage and create condensed versions.\")\n",
        "on_new_run(\"user\", \"Exactly, and we should also limit message length when conversations get lengthy.\")\n",
        "\n",
        "#AI Research Context\n",
        "on_new_run(\"user\", \"Hi there! I'm Maya, working on an AI research assignment.\")\n",
        "on_new_run(\"assistant\", \"Hello Maya! I'd be glad to assist with your research. What's the focus area?\")\n",
        "on_new_run(\"user\", \"It involves implementing automatic text condensation using Groq's language models.\")  # triggers summarization at 3rd run\n",
        "on_new_run(\"assistant\", \"Excellent topic! This requires managing dialogue records and generating brief overviews.\")\n",
        "on_new_run(\"user\", \"Right, plus we need mechanisms to shorten content when it becomes excessive.\")\n",
        "\n",
        "# Academic Project Context\n",
        "on_new_run(\"user\", \"Good day! I'm Sam, and I'm stuck on my coursework assignment.\")\n",
        "on_new_run(\"assistant\", \"Hi Sam! What subject is your assignment focused on?\")\n",
        "on_new_run(\"user\", \"It's about creating intelligent text compression systems with Groq API integration.\")  # triggers summarization at 3rd run\n",
        "on_new_run(\"assistant\", \"Interesting challenge! You'll need to track conversations and produce concise summaries.\")\n",
        "on_new_run(\"user\", \"Precisely, and implement features to control message volume when discussions expand.\")\n",
        "\n",
        "\n",
        "print(\"\\n=== Demo: Truncation by last 2 turns ===\")\n",
        "truncate_by_turns(2)\n",
        "print_history()\n",
        "\n",
        "print(\"\\n=== Demo: Truncation by 50 characters ===\")\n",
        "truncate_by_length(50)\n",
        "print_history()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMv07eDrNk4J",
        "outputId": "a46ff266-212b-4171-8423-e662065d74b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Sample Chat 1 ===\n",
            "Extracted JSON: {'age': 27, 'email': 'priya.patel@techfirm.com', 'location': 'Pune', 'name': 'Priya Patel', 'phone': '8765432109'}\n",
            "Validation: PASS ✅\n",
            "\n",
            "=== Sample Chat 2 ===\n",
            "Extracted JSON: {'age': 32, 'email': 'vikram.k@startup.io', 'location': 'Hyderabad', 'name': 'Vikram Kumar', 'phone': '9234567890'}\n",
            "Validation: PASS ✅\n",
            "\n",
            "=== Sample Chat 3 ===\n",
            "Extracted JSON: {'age': 24, 'email': 'sneha.reddy@company.com', 'location': 'Chennai', 'name': 'Sneha Reddy', 'phone': '9876501234'}\n",
            "Validation: PASS ✅\n",
            "\n",
            "=== Sample Chat 4 ===\n",
            "Extracted JSON: {'age': 29, 'email': 'amit.gupta@business.com', 'location': 'Nice', 'name': 'Amit Gupta', 'phone': '9123478056'}\n",
            "Validation: PASS ✅\n",
            "\n",
            "=== Sample Chat 5 ===\n",
            "Extracted JSON: {'age': 26, 'email': 'kavya.s@consulting.com', 'location': 'Gurgaon', 'name': 'Kavya Sharma', 'phone': '8901234567'}\n",
            "Validation: PASS ✅\n",
            "\n",
            "=== Sample Chat 6 ===\n",
            "Extracted JSON: {'age': 31, 'email': 'rohan.joshi@finance.com', 'location': 'Mumbai', 'name': 'Rohan Joshi', 'phone': '9087654321'}\n",
            "Validation: PASS ✅\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from openai import OpenAI\n",
        "import os, json\n",
        "from jsonschema import validate, ValidationError\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"   # Groq API key\n",
        "os.environ[\"OPENAI_BASE_URL\"] = \"https://api.groq.com/openai/v1\"\n",
        "\n",
        "client = OpenAI()\n",
        "# JSON Schema for extracting details\n",
        "\n",
        "user_info_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"email\": {\"type\": \"string\"},\n",
        "        \"phone\": {\"type\": \"string\"},\n",
        "        \"location\": {\"type\": \"string\"},\n",
        "        \"age\": {\"type\": \"integer\"}\n",
        "    },\n",
        "    \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "}\n",
        "def extract_user_info(conversation_text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"moonshotai/kimi-k2-instruct-0905\",   # Groq supported model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Extract user details into structured JSON.\"},\n",
        "            {\"role\": \"user\", \"content\": conversation_text}\n",
        "        ],\n",
        "        functions=[\n",
        "            {\n",
        "                \"name\": \"extract_user_info\",\n",
        "                \"description\": \"Extracts personal details from conversation\",\n",
        "                \"parameters\": user_info_schema\n",
        "            }\n",
        "        ],\n",
        "        function_call={\"name\": \"extract_user_info\"}\n",
        "    )\n",
        "\n",
        "    args = response.choices[0].message.function_call.arguments\n",
        "    return json.loads(args)\n",
        "def validate_extracted(data):\n",
        "    try:\n",
        "        validate(instance=data, schema=user_info_schema)\n",
        "        return True, None\n",
        "    except ValidationError as e:\n",
        "        return False, str(e)\n",
        "sample_chats = [\n",
        "    \"Hello, I'm Priya Patel, working as a software developer. You can contact me at priya.patel@techfirm.com, my phone is 8765432109, I'm based in Pune, and I'm 27 years old.\",\n",
        "\"Good morning! This is Vikram Kumar, age 32. Feel free to reach out at vikram.k@startup.io or dial 9234567890. I'm currently residing in Hyderabad.\",\n",
        "\"Hi there! I'm Sneha Reddy, 24 years old. My email address is sneha.reddy@company.com, contact number is 9876501234, and I live in Chennai.\",\n",
        "\"Greetings! I'm Amit Gupta from the marketing team. My email is amit.gupta@business.com, phone number is 9123478056, I'm located in Noida, and I'm 29 years old.\",\n",
        "\"Hi, this is Kavya Sharma speaking, I'm 26. You can reach me through kavya.s@consulting.com or call 8901234567. I work from Gurgaon.\",\n",
        "\"Hello! My name is Rohan Joshi, I'm 31 years old. Contact details: rohan.joshi@finance.com, mobile: 9087654321, and I'm based in Mumbai.\"\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "for i, chat in enumerate(sample_chats, 1):\n",
        "    print(f\"\\n=== Sample Chat {i} ===\")\n",
        "    extracted = extract_user_info(chat)\n",
        "    is_valid, error = validate_extracted(extracted)\n",
        "\n",
        "    print(\"Extracted JSON:\", extracted)\n",
        "    print(\"Validation:\", \"PASS ✅\" if is_valid else f\"FAIL ❌ - {error}\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
